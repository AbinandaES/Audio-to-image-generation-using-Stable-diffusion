# Audio-to-image-generation-using-Stable-diffusion
The project explores the new dimensions of interaction and creativity in generative diffusion models. The audio-to-image generation project is built on next-gen Stable Diffusion models and generates images from sound input, unlocking interio design, art, therapy, and education opportunities. The work explored in this project underscores the potential of AI and the transformation it can bring, leading the way for innovations and applications. This system works using a 2 step process: audio-to-text conversion and then using that text, text-to-image generation. By using natural language processing (NLP) and a pre-trained Stable Diffusion model, we set up a smooth pipeline that converts recorded or uploaded audio into high-quality visualized images relevant to the audio.
